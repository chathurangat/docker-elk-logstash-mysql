input {
  jdbc {
    #jdbc connector should be stored in the logstash docker container
    jdbc_driver_library => "/usr/share/logstash/mysql-driver/mysql-connector-java-5.1.47-bin.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://139.162.2.101:3306/employee_db"
    jdbc_user => "root"
    jdbc_password => "root123"
    #logstash will be run in every minute as scheduled below.
    schedule => "* * * * *"
    statement => "SELECT * from employees where status = 'active'"
  }
}

filter {
    # age,password and address fields will not be sent to the elasticsearch
    mutate { remove_field => [ "age", "password","address"] }

    #following sql fields will be renamed/mapped in elasticsearch as follows
    mutate { rename => {"employment_designation" => "designation"} }
    mutate { rename => {"contact_email" => "email"} }
    mutate { rename => {"mobile_number" => "mobile"} }
}

output{
   # starting from elasticsearch 6, only one type/mapping is allowed per index.
   elasticsearch {
   hosts => ["elasticsearch:9200"]
   index => "company_employees"
   # id field of the sql result set will be mapped as the document id
   document_id => "%{id}"
   }
}
